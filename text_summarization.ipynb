{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyM8b1aUPOT4OQu7FwjLfdhf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"],"metadata":{"id":"m3zm1mXQLNxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi\n"],"metadata":{"id":"QvzyvYd5MYNY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import pipeline,set_seed\n","\n","import matplotlib.pyplot as plt\n","from datasets import load_dataset\n","import pandas as pd\n","from datasets import load_dataset , load_metric\n","\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","from tqdm import tqdm\n","import torch\n","\n","nltk.download(\"punkt\")"],"metadata":{"id":"vOvplxIMMneY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"metadata":{"id":"fijO99Q7N2Q4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_ckpt = \"google/pegasus-cnn_dailymail\"\n","tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"],"metadata":{"id":"o3rzHXf3OwYv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"],"metadata":{"id":"pxI_etffPzRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#LOAD OUR DATA\n","dataset_samsum = load_dataset(\"samsum\")\n","dataset_samsum"],"metadata":{"id":"66qVwG8qQIDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n","split_lengths"],"metadata":{"id":"UnzJJCWtl-N8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Features: {dataset_samsum['train'].column_names}\")"],"metadata":{"id":"uK-nAR2ImbC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"\\nDialogue:\")\n","print(dataset_samsum[\"test\"][1][\"dialogue\"])\n","print(\"\\nSummary:\")\n","print(dataset_samsum[\"test\"][1][\"summary\"])"],"metadata":{"id":"c6oOZFCCmtHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dialogue = dataset_samsum['test'][0]['dialogue']\n","dialogue"],"metadata":{"id":"O1m_xldvnhys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe = pipeline('summarization',model = model_ckpt)"],"metadata":{"id":"3Q2_WVuwpoGt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pipe_out = pipe(dialogue)\n","pipe_out"],"metadata":{"id":"6FEaAzpkqIE8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(pipe_out[0]['summary_text'].replace(\".<n>\", \".\\n\"))"],"metadata":{"id":"mfuwzmjrqceL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_batch_sized_chunks(list_of_elements,batch_size):\n","  \"\"\"split the dataset into smaller batches that we can process simultaneously\n","  Yeild successive batch-sized chunks from list_of_elements.\"\"\"\n","  for i in range(0,len(list_of_elements),batch_size):\n","      yield list_of_elements[i : i + batch_size]\n","\n"],"metadata":{"id":"JP-Slv0BrX8z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_metric_on_test_ds(dataset, metric, model, tokenizer, \n","                               batch_size=16, device=device, \n","                               column_text=\"article\", \n","                               column_summary=\"highlights\"):\n","    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n","    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n","\n","    for article_batch, target_batch in tqdm(\n","        zip(article_batches, target_batches), total=len(article_batches)):\n","        \n","        inputs = tokenizer(article_batch, max_length=1024,  truncation=True, \n","                        padding=\"max_length\", return_tensors=\"pt\")\n","        \n","        summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n","                         attention_mask=inputs[\"attention_mask\"].to(device), \n","                         length_penalty=0.8, num_beams=8, max_length=128)\n","        ''' parameter for length penalty ensures that the model does not generate sequences that are too long. '''\n","        \n","        # Finally, we decode the generated texts, \n","        # replace the  token, and add the decoded texts with the references to the metric.\n","        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, \n","                                clean_up_tokenization_spaces=True) \n","               for s in summaries]      \n","        \n","        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n","        \n","        \n","        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n","        \n","    #  Finally compute and return the ROUGE scores.\n","    score = metric.compute()\n","    return score"],"metadata":{"id":"wfgfKl_SsvRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rouge_metric = load_metric('rouge')\n","score = calculate_metric_on_test_ds(dataset_samsum['test'], rouge_metric, model_pegasus, tokenizer, column_text = 'dialogue', column_summary='summary' , batch_size=8)"],"metadata":{"id":"dRYxjleVt_f3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n","rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n","\n","pd.DataFrame(rouge_dict, index = ['pegasus'])"],"metadata":{"id":"7fgNy3DDqqe6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dialogue_token_len = len([tokenizer.encode(s) for s in dataset_samsum['train']['dialogue']])\n","\n","summary_token_len = len([tokenizer.encode(s) for s in dataset_samsum['train']['summary']])\n","\n","\n","fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n","axes[0].hist(dialogue_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n","axes[0].set_title(\"Dialogue Token Length\")\n","axes[0].set_xlabel(\"Length\")\n","axes[0].set_ylabel(\"Count\")\n","\n","axes[1].hist(summary_token_len, bins = 20, color = 'C0', edgecolor = 'C0' )\n","axes[1].set_title(\"Summary Token Length\")\n","axes[1].set_xlabel(\"Length\")\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"9qQ6AxRgF4QP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_examples_to_features(example_batch):\n","    input_encodings = tokenizer(example_batch['dialogue'] , max_length = 1024, truncation = True )\n","    \n","    with tokenizer.as_target_tokenizer():\n","        target_encodings = tokenizer(example_batch['summary'], max_length = 128, truncation = True )\n","        \n","    return {\n","        'input_ids' : input_encodings['input_ids'],\n","        'attention_mask': input_encodings['attention_mask'],\n","        'labels': target_encodings['input_ids']\n","    }\n","    \n","dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features, batched = True)"],"metadata":{"id":"yZt76yZ3F9NX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import DataCollatorForSeq2Seq\n","\n","seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"],"metadata":{"id":"3gfAhneKGCqX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","     "],"metadata":{"id":"dIgD8QUNGISZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/005_BOKTIAR_AHMED_BAPPY/My_classes/FSDS_NOV_10_AM\n","     "],"metadata":{"id":"INyqASm3GKCx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TrainingArguments, Trainer\n","\n","trainer_args = TrainingArguments(\n","    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n","    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","    weight_decay=0.01, logging_steps=10,\n","    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n","    gradient_accumulation_steps=16\n",") "],"metadata":{"id":"6NKeoVStGZf6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = Trainer(model=model_pegasus, args=trainer_args,\n","                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n","                  train_dataset=dataset_samsum_pt[\"train\"], \n","                  eval_dataset=dataset_samsum_pt[\"validation\"])\n","     "],"metadata":{"id":"YywfUNN6Gb9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"SR8stTxvGeH_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = calculate_metric_on_test_ds(\n","    dataset_samsum['test'], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",")\n","\n","rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n","\n","pd.DataFrame(rouge_dict, index = [f'pegasus'] )"],"metadata":{"id":"Y1DJpmivGgg0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_pegasus.save_pretrained(\"pegasus-samsum-model\")\n","     "],"metadata":{"id":"ppl7m6fpGkEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.save_pretrained(\"tokenizer\")"],"metadata":{"id":"rkna9iBqGmcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_samsum = load_dataset(\"samsum\")"],"metadata":{"id":"IGHzOzGsGo4M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")"],"metadata":{"id":"Pi-IOkvZGrJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n","\n","reference = dataset_samsum[\"test\"][0][\"summary\"]\n","     "],"metadata":{"id":"ENbFIOFEGtcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n","\n","pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)"],"metadata":{"id":"r8L1m_xxGvQ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Dialogue:\")\n","print(sample_text)\n","\n","\n","print(\"\\nReference Summary:\")\n","print(reference)\n","\n","\n","print(\"\\nModel Summary:\")\n","print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"],"metadata":{"id":"gcFXT_c6GxMA"},"execution_count":null,"outputs":[]}]}